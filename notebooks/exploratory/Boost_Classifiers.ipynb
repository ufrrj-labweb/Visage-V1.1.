{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste de Classificadores com ajuste de peso e modelos de arvore com up/downsampling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo é testar os modelos XGBoost e adaBoost sem sampling e a floresta aleatoria e arvore de decisão com sampling, analisar qual deles tem a melhor metrica de recall para o banco de dados com todas as 4 tabelas e qual tem o melhor ponto de cotovelo na curva recall-precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar os dados e criar classe de processamento "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando bibliotecas e dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import islice\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_tree\n",
    "\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "import sklearn.metrics as metrics\n",
    "from enelvo.normaliser import Normaliser\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_denuncia_crime=pd.read_csv('/Users/mhctds/Cidade_Social/base de dados/base_apps_denuncia_crime.csv')\n",
    "df_base_rocinha=pd.read_csv('/Users/mhctds/Cidade_Social/base de dados/base_rocinha_df.csv')\n",
    "df_protestos_2013=pd.read_csv('/Users/mhctds/Cidade_Social/base de dados/protestos_2013_df.csv')\n",
    "df_protestos_PMES=pd.read_csv('/Users/mhctds/Cidade_Social/base de dados/protestos_PMES.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criar classe de processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessing:\n",
    "    vect=None\n",
    "    def import_vect(self,vectorizer):\n",
    "        self.vect=vectorizer\n",
    "    def export_vect(self):\n",
    "        pickle.dump(self.vect, open(\"tfidf.pickle\", \"wb\"))\n",
    "    # Junta os dataframes dentro do vetor de dataframes\n",
    "    def append_data(self,df_vector):\n",
    "        df_final=df_vector[0]\n",
    "        df_final=df_final[['text','Total(SUM)','Classe de Violência']]\n",
    "        for df in islice(df_vector, 1, None) :\n",
    "            df=df[['text','Total(SUM)','Classe de Violência']]\n",
    "            df_final=pd.concat([df_final]+[df])\n",
    "        df_final.reset_index()\n",
    "        df_final['text']=df_final['text'].astype('str')\n",
    "        return df_final\n",
    "    \n",
    "    #Normalização usando spacy\n",
    "    def text_normalizer_spacy(self,corpus):\n",
    "        nlp = spacy.load('pt_core_news_sm', disable=['parser', 'ner'])\n",
    "        lemm=[]\n",
    "        for text in tqdm(corpus):\n",
    "            doc = nlp(text)\n",
    "            #tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
    "            tokens = [token.lemma_ for token in doc]\n",
    "            text= ' '.join(tokens)\n",
    "            \n",
    "            lemm.append(text)\n",
    "        return lemm\n",
    "    # Normalização usando enelvo e vetorização usando nltk \n",
    "    def text_preprocessing_nltk(self,corpus):\n",
    "        stop_words=list(nltk_stopwords.words('portuguese'))\n",
    "        norm = Normaliser(tokenizer='readable',sanitize=True)\n",
    "        lemm=[]\n",
    "        for texts in corpus:\n",
    "            lemm.append(norm.normalise(texts))\n",
    "        if self.vect is None:\n",
    "            self.vect=TfidfVectorizer(stop_words=stop_words)\n",
    "            self.vect.fit(corpus)\n",
    "        processed=self.vect.transform(lemm)\n",
    "        return processed\n",
    "    #Vetorização usando nltk\n",
    "    def text_preprocessing_nltk_no_norm(self,corpus):\n",
    "        stop_words=list(nltk_stopwords.words('portuguese'))\n",
    "        if self.vect is None:\n",
    "            self.vect=TfidfVectorizer(stop_words=stop_words)\n",
    "            self.vect.fit(corpus)\n",
    "        processed=self.vect.transform(corpus)\n",
    "        return processed\n",
    "    #Mudar target para valor numerico\n",
    "    def numerical_target(self,target):\n",
    "        target.replace('Not Violence',0,inplace=True)\n",
    "        target.replace('Low',1,inplace=True)\n",
    "        target.replace('Medium',2,inplace=True)\n",
    "        target.replace('High',3,inplace=True)\n",
    "        target.replace('VeryHight',4,inplace=True)\n",
    "        return target\n",
    "    #fraction é a fração que vai sobrar do original, deve ser colocado um valor entre 0 e 1\n",
    "    # Se usado 0.3 por exemplo, perderemos 60% dos registros daquele target, sobrando 30 porcento\n",
    "    def downsample(self,features, target, fraction,value):\n",
    "        features_true = features[target == value]\n",
    "        features_false = features[target != value]\n",
    "        target_true = target[target == value]\n",
    "        target_false = target[target != value]\n",
    "\n",
    "        features_downsampled = pd.concat(\n",
    "            [features_true.sample(frac=fraction, random_state=12345)]\n",
    "            + [features_false]\n",
    "        )\n",
    "        target_downsampled = pd.concat(\n",
    "            [target_true.sample(frac=fraction, random_state=12345)]\n",
    "            + [target_false]\n",
    "        )\n",
    "\n",
    "        return features_downsampled, target_downsampled\n",
    "    # repeat é o numero de vezes que aquele target sera clonado, deve ser um int maior que 1\n",
    "    def upsample(self,features, target, repeat,value):\n",
    "        features_true = features[target == value]\n",
    "        features_false = features[target != value]\n",
    "        target_true = target[target == value]\n",
    "        target_false = target[target != value]\n",
    "\n",
    "        features_upsampled = pd.concat([features_false] + [features_true] * repeat)\n",
    "        target_upsampled = pd.concat([target_false] + [target_true] * repeat)\n",
    "\n",
    "        return features_upsampled, target_upsampled\n",
    "    \n",
    "class MetricsProcessing:\n",
    "    def probability(self,model,test_data,test_target):\n",
    "        probability=model.predict_proba(test_data,test_target)\n",
    "        target_proba=[]\n",
    "        for i in range(len(test_target)):\n",
    "            if(test_target[i]=='High'):\n",
    "                target_proba.append(probability[i,0])\n",
    "            if(test_target[i]=='Low'):\n",
    "                target_proba.append(probability[i,1])\n",
    "            if(test_target[i]=='Medium'):\n",
    "                target_proba.append(probability[i,2])\n",
    "            if(test_target[i]=='Not Violence'):\n",
    "                target_proba.append(probability[i,3])\n",
    "            if(test_target[i]=='VeryHight'):\n",
    "                target_proba.append(probability[i,4])\n",
    "        return target_proba\n",
    "    def probability_class(self,type_class,model,test_data):\n",
    "        probability=model.predict_proba(test_data)\n",
    "        #High:0, low:1, medium:2, not violence:3, VeryHigh:4\n",
    "        return probability[:,type_class]\n",
    "    def prediction_matriz_by_class(self,data):\n",
    "        matriz=pd.DataFrame()\n",
    "        classes=['High','Low','Medium','Not Violence','VeryHight']\n",
    "        for column in classes:\n",
    "            matriz[column]=np.where(data==column,1,0)\n",
    "        return matriz\n",
    "    def binary_goal(self,prediction,target):\n",
    "        vector=pd.Series()\n",
    "        for pred,targ in prediction,target:\n",
    "            if pred == targ:\n",
    "                vector.append(1)\n",
    "            else:\n",
    "                vector.append(0)\n",
    "        return vector\n",
    "    def evaluate_model(self,model, train_features, train_target, test_features, test_target):\n",
    "    \n",
    "        eval_stats = {}\n",
    "        \n",
    "        fig, axs = plt.subplots(1, 3, figsize=(20, 6)) \n",
    "        \n",
    "        for type, features, target in (('train', train_features, train_target), ('test', test_features, test_target)):\n",
    "            \n",
    "            eval_stats[type] = {}\n",
    "        \n",
    "            pred_target = model.predict(features)\n",
    "            pred_proba =  model.predict_proba(features)\n",
    "            test_matriz=self.prediction_matriz_by_class(data=target)\n",
    "            \n",
    "            # F1\n",
    "            #f1_thresholds = np.arange(0, 1.01, 0.05)\n",
    "            #f1_scores = [metrics.f1_score(self.binary_goal(pred_target,target), self.probability(pred_proba,target)>=threshold,average='weighted') for threshold in f1_thresholds]\n",
    "            \n",
    "            #ROC over all micro-media\n",
    "            fpr, tpr, roc_thresholds = metrics.roc_curve(test_matriz.values.ravel(), pred_proba.ravel())\n",
    "            roc_auc = metrics.roc_auc_score(self.binary_goal(pred_target,target), self.probability(pred_proba,target),average='micro')\n",
    "            eval_stats[type]['ROC AUC'] = roc_auc\n",
    "\n",
    "            #Curva de precisão-revocação over all micro-media\n",
    "            precision, recall, pr_thresholds = metrics.precision_recall_curve(test_matriz.values.ravel(), pred_proba.ravel())\n",
    "            aps = metrics.average_precision_score(self.binary_goal(pred_target,target), self.probability(pred_proba,target),average='micro')\n",
    "            eval_stats[type]['APS'] = aps\n",
    "            \n",
    "            \n",
    "            if type == 'train':\n",
    "                color = 'blue'\n",
    "            else:\n",
    "                color = 'green'\n",
    "\n",
    "            # Valor F1\n",
    "            ax = axs[0]\n",
    "            max_f1_score_idx = np.argmax(f1_scores)\n",
    "            ax.plot(f1_thresholds, f1_scores, color=color, label=f'{type}, max={f1_scores[max_f1_score_idx]:.2f} @ {f1_thresholds[max_f1_score_idx]:.2f}')\n",
    "            # definindo cruzamentos para alguns limiares\n",
    "            for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):\n",
    "                closest_value_idx = np.argmin(np.abs(f1_thresholds-threshold))\n",
    "                marker_color = 'orange' if threshold != 0.5 else 'red'\n",
    "                ax.plot(f1_thresholds[closest_value_idx], f1_scores[closest_value_idx], color=marker_color, marker='X', markersize=7)\n",
    "            ax.set_xlim([-0.02, 1.02])    \n",
    "            ax.set_ylim([-0.02, 1.02])\n",
    "            ax.set_xlabel('threshold')\n",
    "            ax.set_ylabel('F1')\n",
    "            ax.legend(loc='lower center')\n",
    "            ax.set_title(f'Valor F1') \n",
    "\n",
    "            # ROC\n",
    "            ax = axs[1]    \n",
    "            ax.plot(fpr, tpr, color=color, label=f'{type}, ROC AUC={roc_auc:.2f}')\n",
    "            # setting crosses for some thresholds\n",
    "            for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):\n",
    "                closest_value_idx = np.argmin(np.abs(roc_thresholds-threshold))\n",
    "                marker_color = 'orange' if threshold != 0.5 else 'red'            \n",
    "                ax.plot(fpr[closest_value_idx], tpr[closest_value_idx], color=marker_color, marker='X', markersize=7)\n",
    "            ax.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "            ax.set_xlim([-0.02, 1.02])    \n",
    "            ax.set_ylim([-0.02, 1.02])\n",
    "            ax.set_xlabel('FPR')\n",
    "            ax.set_ylabel('TPR')\n",
    "            ax.legend(loc='lower center')        \n",
    "            ax.set_title(f'Curva ROC Media')\n",
    "            \n",
    "            # Curva de precisão-revocação\n",
    "            ax = axs[2]\n",
    "            ax.plot(recall, precision, color=color, label=f'{type}, AP={aps:.2f}')\n",
    "            # definindo cruzamentos para alguns limiares\n",
    "            for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):\n",
    "                closest_value_idx = np.argmin(np.abs(pr_thresholds-threshold))\n",
    "                marker_color = 'orange' if threshold != 0.5 else 'red'\n",
    "                ax.plot(recall[closest_value_idx], precision[closest_value_idx], color=marker_color, marker='X', markersize=7)\n",
    "            ax.set_xlim([-0.02, 1.02])    \n",
    "            ax.set_ylim([-0.02, 1.02])\n",
    "            ax.set_xlabel('recall')\n",
    "            ax.set_ylabel('precision')\n",
    "            ax.legend(loc='lower center')\n",
    "            ax.set_title(f'PRC Media')        \n",
    "\n",
    "            eval_stats[type]['Accuracy'] = metrics.accuracy_score(target, pred_target)\n",
    "        \n",
    "        df_eval_stats = pd.DataFrame(eval_stats)\n",
    "        df_eval_stats = df_eval_stats.round(2)\n",
    "        df_eval_stats = df_eval_stats.reindex(index=('Acurácia', 'F1', 'APS', 'ROC AUC'))\n",
    "        \n",
    "        print(df_eval_stats)\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unir dataframes e separar em features e target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2038 entries, 0 to 503\n",
      "Data columns (total 3 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   text                 2038 non-null   object \n",
      " 1   Total(SUM)           2037 non-null   float64\n",
      " 2   Classe de Violência  2038 non-null   object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 63.7+ KB\n",
      "                                                text  Total(SUM)  \\\n",
      "0  RT @tvjornalsbt: \"Morte\" denuncia a precarieda...         8.0   \n",
      "1  RT @tvjornalsbt: \"Morte\" denuncia a precarieda...         8.0   \n",
      "2  \"Morte\" denuncia a precariedade da BR-101, na ...         8.0   \n",
      "3  Terremoto de 7.1 no México. Onde vivo não pass...         7.0   \n",
      "4  RT @vinigrilo1: Moradores com medo e assustado...         8.0   \n",
      "\n",
      "  Classe de Violência  \n",
      "0                High  \n",
      "1                High  \n",
      "2                High  \n",
      "3                High  \n",
      "4                High  \n"
     ]
    }
   ],
   "source": [
    "df_vector=[df_base_rocinha,df_denuncia_crime,df_protestos_2013,df_protestos_PMES]\n",
    "DataProcess=DataProcessing()\n",
    "df_final=DataProcess.append_data(df_vector)\n",
    "df_final.info()\n",
    "print(df_final.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=df_final.drop_duplicates().reset_index()\n",
    "features=DataProcess.text_preprocessing_nltk(df_final['text'])\n",
    "target=df_final['Classe de Violência']\n",
    "train_data, test_data, train_target, test_target = train_test_split(features, target, test_size=0.3, random_state=12345,shuffle=True,stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataProcess.export_vect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 1230 entries, 1392 to 1433\n",
      "Series name: Classe de Violência\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "1230 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 19.2+ KB\n",
      "['Not Violence' 'VeryHight' 'High' 'Low' 'Medium']\n"
     ]
    }
   ],
   "source": [
    "train_target.info()\n",
    "print(train_target.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando Modelos de Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best recall: 0.6818181818181818\n",
      "best accuracy: 0.6818181818181818\n",
      "best f1: 0.5528255528255529\n",
      "best precision: 0.4648760330578512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mhctds/Library/Python/3.11/lib/python/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model=DummyClassifier(strategy=\"most_frequent\")\n",
    "model.fit(train_data.toarray(),train_target)\n",
    "prediction=model.predict(test_data)\n",
    "recall=recall_score(test_target,prediction,average='weighted')\n",
    "acc=accuracy_score(test_target,prediction)\n",
    "f1=f1_score(test_target,prediction,average='weighted')\n",
    "precision=precision_score(test_target,prediction,average='weighted')\n",
    "print('best recall:',recall)\n",
    "print('best accuracy:',acc)\n",
    "print('best f1:',f1)\n",
    "print('best precision:',precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbest_recall=0\\nrecall_list_XGBoost=[]\\nprecision_list_XGBoost=[]\\nxgb_train_target=DataProcessing.numerical_target(train_target)\\nxgb_test_target=DataProcessing.numerical_target(test_target)\\n#Talvez não tenha parametro random_state\\n#Tem parametro learning rate, talvez vale a pena testar\\nfor estimators in tqdm(range(1,100)):\\n    for depth in range(1,15):\\n        model = xgb.XGBClassifier(n_estimators=estimators,max_depth=depth, random_state=12345)\\n        model.fit(train_data,xgb_train_target)\\n        prediction=model.predict(test_data)\\n        recall=recall_score(xgb_test_target,prediction)\\n        precision=precision_score(xgb_test_target,prediction)\\n        recall_list_XGBoost.append(recall)\\n        precision_list_XGBoost.append(precision)\\n        if best_recall<recall:\\n            best_depth=depth\\n            best_recall=recall\\n            best_estimators=estimators\\n            best_acc=accuracy_score(test_target,prediction)\\n            best_f1=f1_score(test_target,prediction)\\n            best_precision=precision\\nprint('best depth:',best_depth)\\nprint('best number of estimators:',best_estimators)\\nprint('best recall:',best_recall)\\nprint('best accuracy:',best_acc)\\nprint('best f1:',best_f1)\\nprint('best precision:',best_precision) \\n\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consertar kernel e dependencias \n",
    "\"\"\"\n",
    "best_recall=0\n",
    "recall_list_XGBoost=[]\n",
    "precision_list_XGBoost=[]\n",
    "xgb_train_target=DataProcessing.numerical_target(train_target)\n",
    "xgb_test_target=DataProcessing.numerical_target(test_target)\n",
    "#Talvez não tenha parametro random_state\n",
    "#Tem parametro learning rate, talvez vale a pena testar\n",
    "for estimators in tqdm(range(1,100)):\n",
    "    for depth in range(1,15):\n",
    "        model = xgb.XGBClassifier(n_estimators=estimators,max_depth=depth, random_state=12345)\n",
    "        model.fit(train_data,xgb_train_target)\n",
    "        prediction=model.predict(test_data)\n",
    "        recall=recall_score(xgb_test_target,prediction)\n",
    "        precision=precision_score(xgb_test_target,prediction)\n",
    "        recall_list_XGBoost.append(recall)\n",
    "        precision_list_XGBoost.append(precision)\n",
    "        if best_recall<recall:\n",
    "            best_depth=depth\n",
    "            best_recall=recall\n",
    "            best_estimators=estimators\n",
    "            best_acc=accuracy_score(test_target,prediction)\n",
    "            best_f1=f1_score(test_target,prediction)\n",
    "            best_precision=precision\n",
    "print('best depth:',best_depth)\n",
    "print('best number of estimators:',best_estimators)\n",
    "print('best recall:',best_recall)\n",
    "print('best accuracy:',best_acc)\n",
    "print('best f1:',best_f1)\n",
    "print('best precision:',best_precision) \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [04:34<00:00,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best depth: 1\n",
      "best number of estimators: 4\n",
      "best recall: 0.7518939393939394\n",
      "best accuracy: 0.7518939393939394\n",
      "best f1: 0.696439906609398\n",
      "best precision: 0.6952480292332154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_recall=0\n",
    "recall_list_adaboost=[]\n",
    "precision_list_adaboost=[]\n",
    "#Talvez não tenha parametro  ou random_state\n",
    "#Talvez tenha parametro learning rate, talvez vale a pena testar\n",
    "for estimators in tqdm(range(1,100)):\n",
    "    for depth in range(1,10):\n",
    "        model = AdaBoostClassifier(n_estimators=estimators, random_state=12345)\n",
    "        model.fit(train_data,train_target)\n",
    "        prediction=model.predict(test_data)\n",
    "        recall=recall_score(test_target,prediction,average='weighted')\n",
    "        precision=precision_score(test_target,prediction,average='weighted',zero_division=0)\n",
    "        recall_list_adaboost.append(recall)\n",
    "        precision_list_adaboost.append(precision)\n",
    "        if best_recall<recall:\n",
    "            best_model=model\n",
    "            best_depth=depth\n",
    "            best_recall=recall\n",
    "            best_estimators=estimators\n",
    "            best_acc=accuracy_score(test_target,prediction)\n",
    "            best_f1=f1_score(test_target,prediction,average='weighted')\n",
    "            best_precision=precision\n",
    "print('best depth:',best_depth)\n",
    "print('best number of estimators:',best_estimators)\n",
    "print('best recall:',best_recall)\n",
    "print('best accuracy:',best_acc)\n",
    "print('best f1:',best_f1)\n",
    "print('best precision:',best_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floresta Aleatoria sem Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:13<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best depth: 29\n",
      "best size: 49\n",
      "best recall: 0.7916666666666666\n",
      "best accuracy: 0.7916666666666666\n",
      "best f1: 0.7482110833482369\n",
      "best precision: 0.7760184976969774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_recall=0\n",
    "recall_list_florest=[]\n",
    "precision_list_florest=[]\n",
    "for size in tqdm(range(1,50)):\n",
    "    for depth in range(1,30):\n",
    "        model=RandomForestClassifier(random_state=123456789,max_depth=depth,n_estimators=size)\n",
    "        model.fit(train_data,train_target)\n",
    "        prediction=model.predict(test_data)\n",
    "        recall=recall_score(test_target,prediction,average='weighted')\n",
    "        precision=precision_score(test_target,prediction,average='weighted',zero_division=0)\n",
    "        recall_list_florest.append(recall)\n",
    "        precision_list_florest.append(precision)\n",
    "        if best_recall<recall:\n",
    "            best_depth=depth\n",
    "            best_recall=recall\n",
    "            best_size=size\n",
    "            best_acc=accuracy_score(test_target,prediction)\n",
    "            best_f1=f1_score(test_target,prediction,average='weighted')\n",
    "            best_precision=precision\n",
    "print('best depth:',best_depth)\n",
    "print('best size:',best_size)\n",
    "print('best recall:',best_recall)\n",
    "print('best accuracy:',best_acc)\n",
    "print('best f1:',best_f1)\n",
    "print('best precision:',best_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arvore de decisão sem Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:04<00:00, 22.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best depth: 73\n",
      "best recall: 0.8200757575757576\n",
      "best accuracy: 0.8200757575757576\n",
      "best f1: 0.8145825710876146\n",
      "best precision: 0.8092480294455772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_recall=0\n",
    "recall_list_tree=[]\n",
    "precision_list_tree=[]\n",
    "for depth in tqdm(range(1,100)):\n",
    "    model=DecisionTreeClassifier(random_state=123456789,max_depth=depth)\n",
    "    model.fit(train_data,train_target)\n",
    "    prediction=model.predict(test_data)\n",
    "    recall=recall_score(test_target,prediction,average='weighted')\n",
    "    precision=precision_score(test_target,prediction,average='weighted',zero_division=0)\n",
    "    recall_list_tree.append(recall)\n",
    "    precision_list_tree.append(precision)\n",
    "    if best_recall<recall:\n",
    "        best_depth=depth\n",
    "        best_recall=recall\n",
    "        best_acc=accuracy_score(test_target,prediction)\n",
    "        best_f1=f1_score(test_target,prediction,average='weighted')\n",
    "        best_precision=precision\n",
    "print('best depth:',best_depth)\n",
    "print('best recall:',best_recall)\n",
    "print('best accuracy:',best_acc)\n",
    "print('best f1:',best_f1)\n",
    "print('best precision:',best_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"DecisionTreeClassificationModel.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive-Bayes sem sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best recall: 0.7329545454545454\n",
      "best accuracy: 0.7329545454545454\n",
      "best f1: 0.7511976381461676\n",
      "best precision: 0.7753840488215488\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(train_data.toarray(),train_target)\n",
    "prediction=model.predict(test_data.toarray())\n",
    "recall=recall_score(test_target,prediction,average='weighted')\n",
    "acc=accuracy_score(test_target,prediction)\n",
    "f1=f1_score(test_target,prediction,average='weighted')\n",
    "precision=precision_score(test_target,prediction,average='weighted')\n",
    "print('best recall:',recall)\n",
    "print('best accuracy:',acc)\n",
    "print('best f1:',f1)\n",
    "print('best precision:',precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"NaiveBayesClassificationModel.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT sem pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'neuralmind/bert-base-portuguese-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df=train_test_split(df_final.drop_duplicates().reset_index(), test_size=0.3, random_state=12345,shuffle=True,stratify=df_final['Classe de Violência'])\n",
    "train_data=train_df['text']\n",
    "train_target=train_df['Classe de Violência']\n",
    "test_data=test_df['text']\n",
    "test_target=test_df['Classe de Violência']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 12345\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "token_lens = []\n",
    "\n",
    "for txt in train_data:\n",
    "  tokens = tokenizer.encode(txt, max_length=512)\n",
    "  token_lens.append(len(tokens))\n",
    "MAX_LEN=max(token_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostsDataset(Dataset):\n",
    "\n",
    "  def __init__(self, posts, targets, tokenizer, max_len):\n",
    "    self.posts = posts\n",
    "    self.targets = targets\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.posts)\n",
    "\n",
    "  def __getitem__(self, item):\n",
    "    post = str(self.posts[item])\n",
    "    target = self.targets[item]\n",
    "\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      post,\n",
    "      add_special_tokens=True,\n",
    "      max_length=self.max_len,\n",
    "      return_token_type_ids=False,\n",
    "      #padding='longest',\n",
    "      pad_to_max_length=True,\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    return {\n",
    "      'post_text': post,\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_mask': encoding['attention_mask'].flatten(),\n",
    "      'targets': torch.tensor(target, dtype=torch.long)\n",
    "    }\n",
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "  numerical_target=DataProcess.numerical_target(df['Classe de Violência'])\n",
    "  ds = PostsDataset(\n",
    "    posts=df.text.to_numpy(),\n",
    "    targets=numerical_target.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "  )\n",
    "\n",
    "  return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4\n",
    "  )\n",
    "def train_epoch(\n",
    "  model,\n",
    "  data_loader,\n",
    "  loss_fn,\n",
    "  optimizer,\n",
    "  device,\n",
    "  scheduler,\n",
    "  n_examples\n",
    "):\n",
    "  model = model.train()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  for d in data_loader:\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device)\n",
    "    targets = d[\"targets\"].to(device)\n",
    "\n",
    "    outputs = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    loss = loss_fn(outputs, targets)\n",
    "\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "  model = model.eval()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "      loss = loss_fn(outputs, targets)\n",
    "\n",
    "      correct_predictions += torch.sum(preds == targets)\n",
    "      losses.append(loss.item())\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "class SentimentClassifier(nn.Module):\n",
    "\n",
    "  def __init__(self, n_classes):\n",
    "    super(SentimentClassifier, self).__init__()\n",
    "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict=False)\n",
    "    self.drop = nn.Dropout(p=0.3)\n",
    "    #The last_hidden_state is a sequence of hidden states of the last layer of the model\n",
    "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "\n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    _, pooled_output = self.bert(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "    output = self.drop(pooled_output)\n",
    "    return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "train_data_loader = create_data_loader(train_df, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(test_df, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.9_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.9_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'PostsDataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      2\u001b[0m data\u001b[38;5;241m.\u001b[39mkeys()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py:439\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py:387\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1040\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1033\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.9_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.9_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.9_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/context.py:288\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.9_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.9_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.9_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentinel \u001b[38;5;241m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = next(iter(train_data_loader))\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtargets\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "print(data['input_ids'].shape)\n",
    "print(data['attention_mask'].shape)\n",
    "print(data['targets'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class_names = ['High', 'Medium', 'Not Violence', 'Very High', 'Low']\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SentimentClassifier(len(class_names))\n",
    "model = model.to(device)\n",
    "EPOCHS = 10\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=3e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.9_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.9_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'PostsDataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:11\u001b[0m\n",
      "Cell \u001b[0;32mIn[70], line 61\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples)\u001b[0m\n\u001b[1;32m     58\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     59\u001b[0m correct_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 61\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m  \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m  \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py:439\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py:387\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1040\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1033\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.9_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.9_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.9_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/context.py:288\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.9_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.9_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.9_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentinel \u001b[38;5;241m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(fp\u001b[38;5;241m.\u001b[39mgetbuffer())\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "\n",
    "  train_acc, train_loss = train_epoch(\n",
    "    model,\n",
    "    train_data_loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    scheduler,\n",
    "    len(train_df)\n",
    "  )\n",
    "\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "  val_acc, val_loss = eval_model(\n",
    "    model,\n",
    "    test_data_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(test_df)\n",
    "  )\n",
    "\n",
    "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "  print()\n",
    "\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['train_loss'].append(train_loss)\n",
    "  history['val_acc'].append(val_acc)\n",
    "  history['val_loss'].append(val_loss)\n",
    "\n",
    "  if val_acc > best_accuracy:\n",
    "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um novo dicionário para armazenar as métricas na CPU\n",
    "metrics_cpu = defaultdict(list)\n",
    "\n",
    "# Copiar cada valor para a CPU e adicioná-lo ao novo dicionário\n",
    "for key, value_list in history.items():\n",
    "    for value in value_list:\n",
    "        if isinstance(value, np.float64):\n",
    "            tensor = torch.from_numpy(np.array(value)).to('cpu')\n",
    "            metrics_cpu[key].append(tensor)\n",
    "        else:\n",
    "            metrics_cpu[key].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_cpu = [tensor.cpu().item() for tensor in history['train_acc']]\n",
    "val_acc_cpu = [tensor.cpu().item() for tensor in history['val_acc']]\n",
    "\n",
    "plt.plot(train_acc_cpu, label='train accuracy')\n",
    "plt.plot(val_acc_cpu, label='validation accuracy')\n",
    "\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def get_predictions(model, data_loader):\n",
    "  model = model.eval()\n",
    "\n",
    "  review_texts = []\n",
    "  predictions = []\n",
    "  prediction_probs = []\n",
    "  real_values = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "\n",
    "      texts = d[\"post_text\"]\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "      probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "      review_texts.extend(texts)\n",
    "      predictions.extend(preds)\n",
    "      prediction_probs.extend(probs)\n",
    "      real_values.extend(targets)\n",
    "\n",
    "  predictions = torch.stack(predictions).cpu()\n",
    "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
    "  real_values = torch.stack(real_values).cpu()\n",
    "  return review_texts, predictions, prediction_probs, real_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_post_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
    "  model,\n",
    "  test_data_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best recall:',recall_score(y_test, y_pred,average='weighted'))\n",
    "print('best accuracy:',accuracy_score(y_test, y_pred))\n",
    "print('best f1:',f1_score(y_test, y_pred,average='weighted'))\n",
    "print('best precision:',precision_score(y_test, y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['High' 'Medium' 'Not Violence' 'VeryHight' 'Low']\n",
      "1199\n",
      "5\n",
      "17\n",
      "93\n",
      "444\n"
     ]
    }
   ],
   "source": [
    "print(target.unique())\n",
    "print(len(target[target=='Not Violence']))\n",
    "print(len(target[target=='Low']))\n",
    "print(len(target[target=='Medium']))\n",
    "print(len(target[target=='High']))\n",
    "print(len(target[target=='VeryHight']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled,garbage=train_test_split(df_final.drop_duplicates().reset_index(), test_size=0.3, random_state=12345,shuffle=True,stratify=df_final['Classe de Violência'])\n",
    "features_sampled,target_sampled=DataProcess.upsample(df_sampled['text'], df_sampled['Classe de Violência'], 240,'Low')\n",
    "features_sampled,target_sampled=DataProcess.upsample(features_sampled,target_sampled, 71,'Medium')\n",
    "features_sampled,target_sampled=DataProcess.upsample(features_sampled,target_sampled, 13,'High')\n",
    "features_sampled,target_sampled=DataProcess.upsample(features_sampled,target_sampled, 3,'VeryHigh')\n",
    "features_sampled=DataProcess.text_preprocessing_nltk(features_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floresta Aleatoria com Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [02:18<00:00,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best depth: 29\n",
      "best size: 21\n",
      "best recall: 0.7632575757575758\n",
      "best accuracy: 0.7632575757575758\n",
      "best f1: 0.7237333848128602\n",
      "best precision: 0.7937946306755943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_recall=0\n",
    "recall_list_florest=[]\n",
    "precision_list_florest=[]\n",
    "for size in tqdm(range(1,50)):\n",
    "    for depth in range(1,30):\n",
    "        model=RandomForestClassifier(random_state=123456789,max_depth=depth,n_estimators=size)\n",
    "        model.fit(features_sampled,target_sampled)\n",
    "        prediction=model.predict(test_data)\n",
    "        recall=recall_score(test_target,prediction,average='weighted')\n",
    "        precision=precision_score(test_target,prediction,average='weighted',zero_division=0)\n",
    "        recall_list_florest.append(recall)\n",
    "        precision_list_florest.append(precision)\n",
    "        if best_recall<recall:\n",
    "            best_model=model\n",
    "            best_depth=depth\n",
    "            best_recall=recall\n",
    "            best_size=size\n",
    "            best_acc=accuracy_score(test_target,prediction)\n",
    "            best_f1=f1_score(test_target,prediction,average='weighted')\n",
    "            best_precision=precision\n",
    "print('best depth:',best_depth)\n",
    "print('best size:',best_size)\n",
    "print('best recall:',best_recall)\n",
    "print('best accuracy:',best_acc)\n",
    "print('best f1:',best_f1)\n",
    "print('best precision:',best_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arvore de decisão com Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:04<00:00, 24.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best depth: 38\n",
      "best recall: 0.7954545454545454\n",
      "best accuracy: 0.7954545454545454\n",
      "best f1: 0.788440383620773\n",
      "best precision: 0.8106343557476484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_recall=0\n",
    "recall_list_tree=[]\n",
    "precision_list_tree=[]\n",
    "for depth in tqdm(range(1,100)):\n",
    "    model=DecisionTreeClassifier(random_state=123456789,max_depth=depth)\n",
    "    model.fit(features_sampled,target_sampled)\n",
    "    prediction=model.predict(test_data)\n",
    "    recall=recall_score(test_target,prediction,average='weighted')\n",
    "    precision=precision_score(test_target,prediction,average='weighted',zero_division=0)\n",
    "    recall_list_tree.append(recall)\n",
    "    precision_list_tree.append(precision)\n",
    "    if best_recall<recall:\n",
    "        best_model=model\n",
    "        best_depth=depth\n",
    "        best_recall=recall\n",
    "        best_acc=accuracy_score(test_target,prediction)\n",
    "        best_f1=f1_score(test_target,prediction,average='weighted')\n",
    "        best_precision=precision\n",
    "print('best depth:',best_depth)\n",
    "print('best recall:',best_recall)\n",
    "print('best accuracy:',best_acc)\n",
    "print('best f1:',best_f1)\n",
    "print('best precision:',best_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive-Bayes com sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best recall: 0.7329545454545454\n",
      "best accuracy: 0.7329545454545454\n",
      "best f1: 0.7511976381461676\n",
      "best precision: 0.7753840488215488\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(features_sampled.toarray(),target_sampled)\n",
    "prediction=model.predict(test_data.toarray())\n",
    "recall=recall_score(test_target,prediction,average='weighted')\n",
    "acc=accuracy_score(test_target,prediction)\n",
    "f1=f1_score(test_target,prediction,average='weighted')\n",
    "precision=precision_score(test_target,prediction,average='weighted',zero_division=0)\n",
    "naive_bayes_probability=model.predict_proba(test_data.toarray())\n",
    "print('best recall:',recall)\n",
    "print('best accuracy:',acc)\n",
    "print('best f1:',f1)\n",
    "print('best precision:',precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(naive_bayes_probability[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mMetricsProcessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_target\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[66], line 142\u001b[0m, in \u001b[0;36mMetricsProcessing.evaluate_model\u001b[0;34m(self, model, train_features, train_target, test_features, test_target)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# F1\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m#f1_thresholds = np.arange(0, 1.01, 0.05)\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m#f1_scores = [metrics.f1_score(self.binary_goal(pred_target,target), self.probability(pred_proba,target)>=threshold,average='weighted') for threshold in f1_thresholds]\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m#ROC over all micro-media\u001b[39;00m\n\u001b[1;32m    141\u001b[0m fpr, tpr, roc_thresholds \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mroc_curve(test_matriz\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mravel(), pred_proba\u001b[38;5;241m.\u001b[39mravel())\n\u001b[0;32m--> 142\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mroc_auc_score(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_goal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobability(pred_proba,target),average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    143\u001b[0m eval_stats[\u001b[38;5;28mtype\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mROC AUC\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m roc_auc\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m#Curva de precisão-revocação over all micro-media\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[66], line 116\u001b[0m, in \u001b[0;36mMetricsProcessing.binary_goal\u001b[0;34m(self, prediction, target)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbinary_goal\u001b[39m(\u001b[38;5;28mself\u001b[39m,prediction,target):\n\u001b[1;32m    115\u001b[0m     vector\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mSeries()\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pred,targ \u001b[38;5;129;01min\u001b[39;00m prediction,target:\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pred \u001b[38;5;241m==\u001b[39m targ:\n\u001b[1;32m    118\u001b[0m             vector\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABkwAAAH/CAYAAAAVC/EHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAss0lEQVR4nO3db2yV53k/8MsBbMMaO8FzhCGGTcQNrZw1WlQhIU3FAbUZDY4FJu2G8ldakVYgG3Tr0CbRTiok69QuifKiGd4SWKWuIFBFVZowYlKlZE2ThSZTq7I4BkOgnjBgJym2gTy/F/nVnYMNHAc/B879+Ujnxbm5H5/r3EJ+vtLXxy7LsiwLAAAAAACAhF1T7AEAAAAAAACKTWECAAAAAAAkT2ECAAAAAAAkT2ECAAAAAAAkT2ECAAAAAAAkT2ECAAAAAAAkT2ECAAAAAAAkT2ECAAAAAAAkT2ECAAAAAAAkr+DCpKOjI771rW/F5z73uXj88ccvur+zszMWLlwYkydPjsbGxtizZ8+YBgUAiJBFAIDikkUAoHQVXJgsXbo0nnnmmdi5c2f09PRccO/Zs2fjjjvuiI9+9KPR0dERa9asibvuuis6OjrGPDAAkDZZBAAoJlkEAEpXwYXJq6++Gtu3b48pU6ZcdO/3vve96OnpiX/6p3+K6dOnx4MPPhhNTU2X9BMYAAAjkUUAgGKSRQCgdBVcmJSVlV3y3m3btsW8efOivLx8aG3+/PmxdevWQl8WACAiZBEAoLhkEQAoXRPH84t3dXXFrbfeOmytvr4+jh07FmfOnIlJkyaNeN3AwEAMDAwMPX/vvffixIkTUVNTU1AwAYBSlmVZvP322zF9+vS45pqCfwYiCbIIAIwfWeTiZBEAGD/jkUXGtTA5fvx4VFZWDlurrKyMLMuip6cnpk2bNuJ1GzdujK9+9avjORoAlIzDhw/HjTfeWOwxrkiyCACMP1lkdLIIAIy/y5lFxrUwqa2tjf7+/mFrp0+fjrKysqipqRn1unXr1sWaNWuGnvf29sbMmTPj8OHDUVVVNW7zAsDVpK+vL+rr6+Paa68t9ihXLFkEAMaPLHJxsggAjJ/xyCLjWpjMmjUrjhw5Mmytq6sr6urqRv3YaURERUVFVFRUnLdeVVUlGADAB/i1DKOTRQBg/Mkio5NFAGD8Xc4sMq6/ZLS1tTV+/OMfx+Dg4NDac889F62treP5sgAAESGLAADFJYsAwNWl4MKkr68vTp06FVmWRX9/f5w6dWro46X33ntvLFiwYGjv4sWL43d/93dj7dq1cezYsfjnf/7n+NGPfhSrVq26fO8AAEiKLAIAFJMsAgClq+DC5A/+4A/i+uuvjxMnTsQjjzwS119/fTz88MMR8f7HSjs6Oob2Tpw4MX7wgx/Ef//3f8fv//7vx2OPPRbf+9734qabbrp87wAASIosAgAUkywCAKWrLMuyrNhDXExfX19UV1dHb2+v39UJAP+f+2N+nDUAnM/9MT/OGgDONx73x3H9GyYAAAAAAABXA4UJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQPIUJAAAAAACQvDEVJrt3747GxsaYPHlyLFy4MA4ePHjB/YcPH46lS5fG1KlTo7a2Nh588MF49913x/LSAACyCABQVLIIAJSmgguTAwcOREtLS6xduzY6OjqioaEhFi1aFOfOnRv1miVLlsTUqVPjZz/7WXz/+9+PvXv3xvr16z/U4ABAmmQRAKCYZBEAKF0FFyaPP/543H777fHAAw/E9OnT49FHH43u7u7YuXPniPtPnDgRL7/8cjz00ENRX18fc+fOjaVLl8aBAwc+9PAAQHpkEQCgmGQRAChdBRcm27Zti6ampqHn5eXlMW/evNi6deuI+6+99tqora2NJ554IrIsi3PnzkV7e3ssW7Zs7FMDAMmSRQCAYpJFAKB0TSxk8+DgYHR3d0d9ff2w9fr6+njttddGvGbSpEnx9NNPx5IlS6KzszOqqqris5/9bNxzzz1jnxoASJIsAgAUkywCAKWtoE+Y9PT0RJZlUVlZOWy9srIyjh8/fsFrZ8yYEf39/bF9+/Z455134uzZs6PuHRgYiL6+vmEPAABZBAAoJlkEAEpbQYVJTU1NlJWVRX9//7D106dPR21t7YjX/PKXv4xly5bFv//7v8fevXvj0Ucfjcceeyz+/M//fNTX2bhxY1RXVw89PviTGwBAmmQRAKCYZBEAKG0FFSbl5eVRV1cXR44cGbbe1dUVM2fOHPGap59+OubMmRO33XZbRER88YtfjPXr10dbW1u8++67I16zbt266O3tHXocPny4kDEBgBIliwAAxSSLAEBpK/iPvre2tkZ7e/vQ8/7+/ti3b1+0traOuH9gYCBOnjw5bG3WrFlRVlYWZWVlI15TUVERVVVVwx4AABGyCABQXLIIAJSugguTlStXxp49e2LLli1x9OjRWL16dUybNi2am5sjImLBggVx7733Du1vaWmJgwcPxrp16+Lw4cPx4osvxte+9rVYtmxZTJky5fK9EwAgCbIIAFBMsggAlK6CC5OGhobYsWNHbNiwIWbPnh2dnZ2xa9eumDBhQkREdHR0RFdX19D+P/qjP4pt27bFs88+G3PmzInPf/7zsXjx4ti0adPlexcAQDJkEQCgmGQRAChdZVmWZcUe4mL6+vqiuro6ent7fQwVAP4/98f8OGsAOJ/7Y36cNQCcbzzujwV/wgQAAAAAAKDUKEwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkjakw2b17dzQ2NsbkyZNj4cKFcfDgwQvuP3bsWCxfvjymTp0aH/nIR+KTn/xk/PSnPx3LSwMAyCIAQFHJIgBQmgouTA4cOBAtLS2xdu3a6OjoiIaGhli0aFGcO3duxP2//vWvo6mpKbIsi5deeilee+21WL16dUycOPFDDw8ApEcWAQCKSRYBgNJVlmVZVsgFq1atioMHD8bOnTsjImJwcDDq6uqira0tWlpaztv/zW9+M77xjW/Em2++GZMmTRrTkH19fVFdXR29vb1RVVU1pq8BAKUm1fujLAIAV4ZU74+yCABcGcbj/ljwJ0y2bdsWTU1NQ8/Ly8tj3rx5sXXr1hH379ixIxYtWjTmUAAA8H/JIgBAMckiAFC6CipMBgcHo7u7O+rr64et19fXx6FDh0a85uc//3nceOONsXbt2qivr49bb701nnzyyQu+zsDAQPT19Q17AADIIgBAMckiAFDaCipMenp6IsuyqKysHLZeWVkZx48fH/GaU6dOxWOPPRYzZsyIXbt2xfLly2PFihXx7W9/e9TX2bhxY1RXVw89PhhEAIA0ySIAQDHJIgBQ2goqTGpqaqKsrCz6+/uHrZ8+fTpqa2tHvKa8vDyam5tjzZo10djYGH/1V38VTU1NsWnTplFfZ926ddHb2zv0OHz4cCFjAgAlShYBAIpJFgGA0jaxkM3l5eVRV1cXR44cGbbe1dUVM2fOHPGaWbNmxbRp04atffzjH4/nn39+1NepqKiIioqKQkYDABIgiwAAxSSLAEBpK/iPvre2tkZ7e/vQ8/7+/ti3b1+0traOuH/BggXx4osvDlvr7OyMj33sY4W+NACALAIAFJUsAgClq+DCZOXKlbFnz57YsmVLHD16NFavXh3Tpk2L5ubmiHg/CNx7771D+//yL/8yfvKTn8TGjRujq6sr/uVf/iWeffbZ+PKXv3z53gUAkAxZBAAoJlkEAEpXwYVJQ0ND7NixIzZs2BCzZ8+Ozs7O2LVrV0yYMCEiIjo6OqKrq2to/+zZs+MHP/hBfPe7342Ghob4h3/4h/jud78bt9122+V7FwBAMmQRAKCYZBEAKF1lWZZlxR7iYvr6+qK6ujp6e3ujqqqq2OMAwBXB/TE/zhoAzuf+mB9nDQDnG4/7Y8GfMAEAAAAAACg1ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5YypMdu/eHY2NjTF58uRYuHBhHDx48JKue/vtt6O+vj7uv//+sbwsAEBEyCIAQHHJIgBQmgouTA4cOBAtLS2xdu3a6OjoiIaGhli0aFGcO3fuoteuW7cu3nrrrTENCgAQIYsAAMUliwBA6Sq4MHn88cfj9ttvjwceeCCmT58ejz76aHR3d8fOnTsveN1//ud/xlNPPRV/+qd/OuZhAQBkEQCgmGQRAChdBRcm27Zti6ampqHn5eXlMW/evNi6deuo15w5cya+8IUvxPr16+Omm24a26QAACGLAADFJYsAQOkqqDAZHByM7u7uqK+vH7ZeX18fhw4dGvW6r3/961FeXh5r1qy5pNcZGBiIvr6+YQ8AAFkEACgmWQQASltBhUlPT09kWRaVlZXD1isrK+P48eMjXvPGG2/Eww8/HG1tbTFhwoRLep2NGzdGdXX10OODQQQASJMsAgAUkywCAKWtoMKkpqYmysrKor+/f9j66dOno7a2dsRrVqxYEatWrYpPfOITl/w669ati97e3qHH4cOHCxkTAChRsggAUEyyCACUtomFbC4vL4+6uro4cuTIsPWurq6YOXPmefsPHToUzz33XDz//PPxyCOPRETEe++9FxER//Zv/xZnz54d8XUqKiqioqKikNEAgATIIgBAMckiAFDaCv6j762trdHe3j70vL+/P/bt2xetra3n7Z0+fXq8/vrrsX///qFHc3NzNDc3x/79+z/U4ABAmmQRAKCYZBEAKF0FfcIkImLlypVx6623xpYtW2LBggXxla98JaZNmxbNzc0REbFgwYKYMWNGbN68OSZNmhSNjY3Drr/uuusiIs5bBwC4FLIIAFBMsggAlK6CP2HS0NAQO3bsiA0bNsTs2bOjs7Mzdu3aNfSHyzo6OqKrq+uyDwoAECGLAADFJYsAQOkqy7IsK/YQF9PX1xfV1dXR29sbVVVVxR4HAK4I7o/5cdYAcD73x/w4awA433jcHwv+hAkAAAAAAECpUZgAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJU5gAAAAAAADJG1Nhsnv37mhsbIzJkyfHwoUL4+DBg6Pufemll+LOO++MG264Ia677rq466674tChQ2OdFwBAFgEAikoWAYDSVHBhcuDAgWhpaYm1a9dGR0dHNDQ0xKJFi+LcuXMj7n/55ZejqakpXnjhhXjhhReiu7s7mpubR90PAHAhsggAUEyyCACUrrIsy7JCLli1alUcPHgwdu7cGRERg4ODUVdXF21tbdHS0nLR6/fs2RMLFy6MX/ziFzFnzpxLes2+vr6orq6O3t7eqKqqKmRcAChZqd4fZREAuDKken+URQDgyjAe98eCP2Gybdu2aGpqGnpeXl4e8+bNi61bt17S9RUVFRERcfr06UJfGgBAFgEAikoWAYDSNbGQzYODg9Hd3R319fXD1uvr6+O11167pK/xne98J6ZPnx633HLLqHsGBgZiYGBg6HlfX18hYwIAJUoWAQCKSRYBgNJW0CdMenp6IsuyqKysHLZeWVkZx48fv+j1zz77bGzatCna2tpi4sTRu5qNGzdGdXX10OODQQQASJMsAgAUkywCAKWtoMKkpqYmysrKor+/f9j66dOno7a29oLX7t27N+6+++7YvHlz3HHHHRfcu27duujt7R16HD58uJAxAYASJYsAAMUkiwBAaSvoV3KVl5dHXV1dHDlyZNh6V1dXzJw5c9TrXnnllWhpaYm2trZYunTpRV+noqJi6Hd6AgD8hiwCABSTLAIApa3gP/re2toa7e3tQ8/7+/tj37590draOuL+vr6+WLJkSTz00EOXFAoAAC5EFgEAikkWAYDSVXBhsnLlytizZ09s2bIljh49GqtXr45p06ZFc3NzREQsWLAg7r333qH9X/va1+J///d/Y8WKFXHq1Kmhx9mzZy/fuwAAkiGLAADFJIsAQOkquDBpaGiIHTt2xIYNG2L27NnR2dkZu3btigkTJkREREdHR3R1dQ3t/8lPfhL9/f0xY8aMuP7664ceL7zwwuV7FwBAMmQRAKCYZBEAKF1lWZZlxR7iYvr6+qK6ujp6e3ujqqqq2OMAwBXB/TE/zhoAzuf+mB9nDQDnG4/7Y8GfMAEAAAAAACg1ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5YypMdu/eHY2NjTF58uRYuHBhHDx48IL7X3311Zg7d25Mnjw55s6dG/v37x/LywIARIQsAgAUlywCAKWp4MLkwIED0dLSEmvXro2Ojo5oaGiIRYsWxblz50bcf+LEifj0pz8dzc3N8eabb8bixYvjM5/5TJw6derDzg4AJEgWAQCKSRYBgNJVcGHy+OOPx+233x4PPPBATJ8+PR599NHo7u6OnTt3jrj/X//1X6Ouri7+9m//Nurq6uLv/u7v4oYbboinnnrqw84OACRIFgEAikkWAYDSVXBhsm3btmhqahp6Xl5eHvPmzYutW7eOun/+/PnD1ubPnz/qfgCAC5FFAIBikkUAoHRNLGTz4OBgdHd3R319/bD1+vr6eO2110a8pqurK5YsWXLe/h07doz6OgMDAzEwMDD0vLe3NyIi+vr6ChkXAErab+6LWZYVeZL8yCIAcOWQRX5LFgGA/I1HFimoMOnp6Yksy6KysnLYemVlZRw/fnzEa44fP17Q/oiIjRs3xle/+tXz1j8YSACA9+/P1dXVxR4jF7IIAFx5ZBFZBACK6XJmkYIKk5qamigrK4v+/v5h66dPn47a2toRr6mtrS1of0TEunXrYs2aNUPPT506FbNmzYqurq5kQlix9PX1RX19fRw+fDiqqqqKPU5Jc9b5cdb5cdb56u3tjZkzZ8bUqVOLPUpuZJHS5/tIfpx1fpx1fpx1vmSR35JFSofvI/lx1vlx1vly3vkZjyxSUGFSXl4edXV1ceTIkWHrXV1dMXPmzBGvmTVrVkH7IyIqKiqioqLivPXq6mr/yXJSVVXlrHPirPPjrPPjrPN1zTUF/0myq5Yskg7fR/LjrPPjrPPjrPMli8gipcj3kfw46/w463w57/xczixS8FdqbW2N9vb2oef9/f2xb9++aG1tvaT9ERHt7e2j7gcAuBBZBAAoJlkEAEpXwYXJypUrY8+ePbFly5Y4evRorF69OqZNmxbNzc0REbFgwYK49957h/bff//98atf/SoeeeSR+NWvfhVf+cpX4vjx43H//fdftjcBAKRDFgEAikkWAYDSVXBh0tDQEDt27IgNGzbE7Nmzo7OzM3bt2hUTJkyIiIiOjo7o6uoa2n/99dfHD3/4w9i6dWv83u/9Xvzwhz+MZ555Jq6//vpLfs2KiopYv379iB9H5fJy1vlx1vlx1vlx1vlK9bxlkdLmrPPjrPPjrPPjrPOV6nnLIqXNWefHWefHWefLeednPM66LMuy7LJ9NQAAAAAAgKtQOn+ZDQAAAAAAYBQKEwAAAAAAIHkKEwAAAAAAIHlXTGGye/fuaGxsjMmTJ8fChQvj4MGDF9z/6quvxty5c2Py5Mkxd+7c2L9/fy5zloJCzvqll16KO++8M2644Ya47rrr4q677opDhw7lN+xVrtD/17/x9ttvR319fdx///3jOl8pKfSsjx07FsuXL4+pU6fGRz7ykfjkJz8ZP/3pT/MZ9ipX6FkfPnw4li5dGlOnTo3a2tp48MEH4913381n2KtcR0dHfOtb34rPfe5z8fjjj190f2dnZyxcuDAmT54cjY2NsWfPnhymLB2ySH5kkfzIIvmRRfIji+RHFsmXLJIfWSQ/skh+ZJH8yCL5KUYWuSIKkwMHDkRLS0usXbs2Ojo6oqGhIRYtWhTnzp0bcf+JEyfi05/+dDQ3N8ebb74Zixcvjs985jNx6tSpfAe/ChV61i+//HI0NTXFCy+8EC+88EJ0d3dHc3PzqPv5rULP+v9at25dvPXWWzlMWRoKPetf//rX0dTUFFmWxUsvvRSvvfZarF69OiZOnJjz5Fefsfy/XrJkSUydOjV+9rOfxfe///3Yu3dvrF+/Psepr15Lly6NZ555Jnbu3Bk9PT0X3Hv27Nm444474qMf/Wh0dHTEmjVr4q677oqOjo6cpr26ySL5kUXyI4vkRxbJjyySL1kkP7JIfmSR/Mgi+ZFF8iOL5KsoWSS7AqxcuTK78847h54PDAxkU6dOzXbs2DHi/n/8x3/MbrnllmFrjY2N2Te/+c1xnLI0FHrWH/Qf//EfWURkv/jFL8ZpwtIx1rN+8cUXs9/5nd/Jli9fnt13333jO2SJKPSsv/GNb2Q33nhjNjg4mNOEpaPQs+7p6ckiInv99deH1r70pS9lixcvHu9RS8J7772XZVmW1dTUZOvXr7/g3m3btmU1NTXZwMDA0Nqdd96ZPfTQQ+M4YemQRfIji+RHFsmPLJIfWSRfskh+ZJH8yCL5kUXyI4vkRxbJVzGyyBXxCZNt27ZFU1PT0PPy8vKYN29ebN26ddT98+fPH7Y2f/78UffzW4We9QdVVFRERMTp06fHZb5SMpazPnPmTHzhC1+I9evXx0033ZTHmCWh0LPesWNHLFq0KCZNmpTXiCWj0LO+9tpro7a2Np544onIsizOnTsX7e3tsWzZsrxGvqqVlZVd8t5t27bFvHnzory8fGjNvfHSySL5kUXyI4vkRxbJjyySL1kkP7JIfmSR/Mgi+ZFF8iOL5KsYWaTohcng4GB0d3dHfX39sPX6+vpRfydkV1dXQft531jO+oO+853vxPTp0+OWW24ZjxFLxljP+utf/3qUl5fHmjVrxnvEkjGWs/75z38eN954Y6xduzbq6+vj1ltvjSeffDKPca9qYznrSZMmxdNPPx1PPfVU/PEf/3H8yZ/8SXz2s5+Ne+65J4+RkzLavfHYsWNx5syZIk11dZBF8iOL5EcWyY8skh9Z5Momi4ydLJIfWSQ/skh+ZJH8yCJXtsuVRYpemPT09ESWZVFZWTlsvbKyMo4fPz7iNcePHy9oP+8by1n/X88++2xs2rQp2tra/E7DixjLWb/xxhvx8MMPR1tbW0yYMCGPMUvCWM761KlT8dhjj8WMGTNi165dsXz58lixYkV8+9vfzmPkq9aH+R4yY8aM6O/vj+3bt8c777wTZ8+eHc9RkzTavTHLsov+ns/UySL5kUXyI4vkRxbJjyxyZZNFxk4WyY8skh9ZJD+ySH5kkSvb5coiRf/uXlNTE2VlZdHf3z9s/fTp01FbWzviNbW1tQXt531jOevf2Lt3b9x9992xefPmuOOOO8ZzzJIwlrNesWJFrFq1Kj7xiU/kMWLJGMtZl5eXR3Nz89BPrDQ2NsauXbti06ZNsXz58nGf+Wo1lrP+5S9/GcuWLYvnn38+brvttnjiiSfiL/7iL+Ltt9/20yuX2Wj3xrKysqipqSnSVFcHWSQ/skh+ZJH8yCL5kUWubLLI2Mki+ZFF8iOL5EcWyY8scmW7XFmk6J8wKS8vj7q6ujhy5Miw9a6urpg5c+aI18yaNaug/bxvLGcdEfHKK69ES0tLtLW1xd133z3eY5aEQs/60KFD8dxzz8UjjzwSEydOjIkTJ8bf//3fx+bNm/3UykWM9XvItGnThq19/OMf99NYFzGWs3766adjzpw5cdttt0VExBe/+MVYv359tLW1xbvvvjvuM6dktHtjXV2d30t7EbJIfmSR/Mgi+ZFF8iOLXNlkkbGTRfIji+RHFsmPLJIfWeTKdrmySNELk4iI1tbWaG9vH3re398f+/bti9bW1kvaHxHR3t4+6n5+q9Cz7uvriyVLlsRDDz0US5cuzWvMklDIWU+fPj1ef/312L9//9Cjubk5mpubY//+/TlOfXUq9P/1ggUL4sUXXxy21tnZGR/72MfGdc5SUOhZDwwMxMmTJ4etzZo1K8rKygr6w11cXGtra/z4xz+OwcHBobXnnnvOvfESySL5kUXyI4vkRxbJjyxy5ZJFPhxZJD+ySH5kkfzIIvmRRa5cly2LZFeAAwcOZFOmTMk2b96cvfXWW9mf/dmfZXPmzMnOnj2bZVmW3X777dk999wztP/EiRNZbW1t9vDDD2fHjh3L1q9fn9XW1mYnTpwo1lu4ahR61n/913+dVVZWZm+99VZ28uTJoceZM2eK9RauGoWe9Qfdd9992X333ZfTtFe3Qs/6jTfeyKZMmZJt2LAhO3ToUNbW1pZNnDgxe/nll4v1Fq4ahZ71j370o+yaa67J/uZv/ibr6urK9u3bl918883Z5z//+WK9hatKb29vdvLkyWzq1KnZl7/85ezkyZPZ6dOnsyzLsnvuuSe7/fbbh/aeOXMmu/nmm7OVK1dmR48ezZ588slsypQp2f/8z/8Ua/yriiySH1kkP7JIfmSR/Mgi+ZJF8iOL5EcWyY8skh9ZJD+ySL6KkUWuiMIky7LsmWeeyebMmZNVVlZmCxcuzDo7O4f+bdasWdmnPvWpYftfeeWV7LbbbssqKiqyuXPnZv/1X/+V78BXsULO+lOf+lQWEec92tvbc5/7alTo/+v/SzAoTKFnvXfv3uzWW2/NysvLs5tvvjnbvn17vgNfxQo96+3bt2d/+Id/mE2ZMiWbOXNm9qUvfSl755138h36KjVr1qzzvv+uX78+y7L3vz/PmjVr2P6Ojo5s/vz5WUVFRdbY2Jjt3r07/6GvYrJIfmSR/Mgi+ZFF8iOL5EcWyZcskh9ZJD+ySH5kkfzIIvkpRhYpy7IsG8tHXAAAAAAAAErFFfE3TAAAAAAAAIpJYQIAAAAAACRPYQIAAAAAACRPYQIAAAAAACRPYQIAAAAAACRPYQIAAAAAACRPYQIAAAAAACRPYQIAAAAAACRPYQIAAAAAACRPYQIAAAAAACRPYQIAAAAAACRPYQIAAAAAACTv/wFWqIa4m72urwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 2000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MetricsProcessing().evaluate_model(model,train_data.toarray(),train_target,test_data.toarray(),test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC e avaliação dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por enquanto o melhor modelo entre eles, sem contar o XGBoost, parece ser a arvore de decisão.\n",
    "\n",
    "Parece valer a pena testar a vetorização com por NILC quando testarmos regressão.\n",
    "\n",
    "Normalização da uma pequena melhora em alguns dos modelos, mas talvez seja por coincidencia (a seed ser boa para aquele novo formato de matriz especifica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

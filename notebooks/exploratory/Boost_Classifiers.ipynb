{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste de Classificadores com ajuste de peso e modelos de arvore com up/downsampling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo é testar os modelos XGBoost e adaBoost sem sampling e a floresta aleatoria e arvore de decisão com sampling, analisar qual deles tem a melhor metrica de recall para o banco de dados com todas as 4 tabelas e qual tem o melhor ponto de cotovelo na curva recall-precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar os dados e criar classe de processamento "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando bibliotecas e dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import islice\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_tree\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from enelvo.normaliser import Normaliser\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_denuncia_crime=pd.read_csv('/Users/mhctds/Cidade_Social/base de dados/base_apps_denuncia_crime.csv')\n",
    "df_base_rocinha=pd.read_csv('/Users/mhctds/Cidade_Social/base de dados/base_rocinha_df.csv')\n",
    "df_protestos_2013=pd.read_csv('/Users/mhctds/Cidade_Social/base de dados/protestos_2013_df.csv')\n",
    "df_protestos_PMES=pd.read_csv('/Users/mhctds/Cidade_Social/base de dados/protestos_PMES.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criar classe de processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessing:\n",
    "    vect=None\n",
    "    # Junta os dataframes dentro do vetor de dataframes\n",
    "    def append_data(self,df_vector):\n",
    "        df_final=df_vector[0]\n",
    "        df_final=df_final[['text','Total(SUM)','Classe de Violência']]\n",
    "        for df in islice(df_vector, 1, None) :\n",
    "            df=df[['text','Total(SUM)','Classe de Violência']]\n",
    "            df_final=pd.concat([df_final]+[df])\n",
    "        df_final.reset_index()\n",
    "        df_final['text']=df_final['text'].astype('str')\n",
    "        return df_final\n",
    "    \n",
    "    #Normalização usando spacy\n",
    "    def text_normalizer_spacy(self,corpus):\n",
    "        nlp = spacy.load('pt_core_news_sm', disable=['parser', 'ner'])\n",
    "        lemm=[]\n",
    "        for text in tqdm(corpus):\n",
    "            doc = nlp(text)\n",
    "            #tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
    "            tokens = [token.lemma_ for token in doc]\n",
    "            text= ' '.join(tokens)\n",
    "            \n",
    "            lemm.append(text)\n",
    "        return lemm\n",
    "    # Normalização usando enelvo e vetorização usando nltk \n",
    "    def text_preprocessing_nltk(self,corpus):\n",
    "        stop_words=list(nltk_stopwords.words('portuguese'))\n",
    "        norm = Normaliser(tokenizer='readable',sanitize=True)\n",
    "        lemm=[]\n",
    "        for texts in corpus:\n",
    "            lemm.append(norm.normalise(texts))\n",
    "        if self.vect is None:\n",
    "            self.vect=TfidfVectorizer(stop_words=stop_words)\n",
    "            self.vect.fit(corpus)\n",
    "        processed=self.vect.transform(lemm)\n",
    "        return processed\n",
    "    #Vetorização usando nltk\n",
    "    def text_preprocessing_nltk_no_norm(self,corpus):\n",
    "        stop_words=list(nltk_stopwords.words('portuguese'))\n",
    "        if self.vect is None:\n",
    "            self.vect=TfidfVectorizer(stop_words=stop_words)\n",
    "            self.vect.fit(corpus)\n",
    "        processed=self.vect.transform(corpus)\n",
    "        return processed\n",
    "    #Mudar target para valor numerico\n",
    "    def numerical_target(target):\n",
    "        target.replace('Not Violence',0,inplace=True)\n",
    "        target.replace('Low',1,inplace=True)\n",
    "        target.replace('Medium',2,inplace=True)\n",
    "        target.replace('High',3,inplace=True)\n",
    "        target.replace('VeryHight',4,inplace=True)\n",
    "        return target\n",
    "    #fraction é a fração que vai sobrar do original, deve ser colocado um valor entre 0 e 1\n",
    "    # Se usado 0.3 por exemplo, perderemos 60% dos registros daquele target, sobrando 30 porcento\n",
    "    def downsample(self,features, target, fraction,value):\n",
    "        features_true = features[target == value]\n",
    "        features_false = features[target != value]\n",
    "        target_true = target[target == value]\n",
    "        target_false = target[target != value]\n",
    "\n",
    "        features_downsampled = pd.concat(\n",
    "            [features_true.sample(frac=fraction, random_state=12345)]\n",
    "            + [features_false]\n",
    "        )\n",
    "        target_downsampled = pd.concat(\n",
    "            [target_true.sample(frac=fraction, random_state=12345)]\n",
    "            + [target_false]\n",
    "        )\n",
    "\n",
    "        return features_downsampled, target_downsampled\n",
    "    # repeat é o numero de vezes que aquele target sera clonado, deve ser um int maior que 1\n",
    "    def upsample(self,features, target, repeat,value):\n",
    "        features_true = features[target == value]\n",
    "        features_false = features[target != value]\n",
    "        target_true = target[target == value]\n",
    "        target_false = target[target != value]\n",
    "\n",
    "        features_upsampled = pd.concat([features_false] + [features_true] * repeat)\n",
    "        target_upsampled = pd.concat([target_false] + [target_true] * repeat)\n",
    "\n",
    "        return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unir dataframes e separar em features e target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2038 entries, 0 to 503\n",
      "Data columns (total 3 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   text                 2038 non-null   object \n",
      " 1   Total(SUM)           2037 non-null   float64\n",
      " 2   Classe de Violência  2038 non-null   object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 63.7+ KB\n",
      "                                                text  Total(SUM)  \\\n",
      "0  RT @tvjornalsbt: \"Morte\" denuncia a precarieda...         8.0   \n",
      "1  RT @tvjornalsbt: \"Morte\" denuncia a precarieda...         8.0   \n",
      "2  \"Morte\" denuncia a precariedade da BR-101, na ...         8.0   \n",
      "3  Terremoto de 7.1 no México. Onde vivo não pass...         7.0   \n",
      "4  RT @vinigrilo1: Moradores com medo e assustado...         8.0   \n",
      "\n",
      "  Classe de Violência  \n",
      "0                High  \n",
      "1                High  \n",
      "2                High  \n",
      "3                High  \n",
      "4                High  \n"
     ]
    }
   ],
   "source": [
    "df_vector=[df_base_rocinha,df_denuncia_crime,df_protestos_2013,df_protestos_PMES]\n",
    "DataProcess=DataProcessing()\n",
    "df_final=DataProcess.append_data(df_vector)\n",
    "df_final.info()\n",
    "print(df_final.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=df_final.drop_duplicates().reset_index()\n",
    "features=DataProcess.text_preprocessing_nltk(df_final['text'])\n",
    "target=df_final['Classe de Violência']\n",
    "train_data, test_data, train_target, test_target = train_test_split(features, target, test_size=0.3, random_state=12345,shuffle=True,stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 1230 entries, 1392 to 1433\n",
      "Series name: Classe de Violência\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "1230 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 19.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train_target.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando Modelos de Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best recall: 0.6818181818181818\n",
      "best accuracy: 0.6818181818181818\n",
      "best f1: 0.5528255528255529\n",
      "best precision: 0.4648760330578512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mhctds/Library/Python/3.11/lib/python/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model=DummyClassifier(strategy=\"most_frequent\")\n",
    "model.fit(train_data.toarray(),train_target)\n",
    "prediction=model.predict(test_data)\n",
    "recall=recall_score(test_target,prediction,average='weighted')\n",
    "acc=accuracy_score(test_target,prediction)\n",
    "f1=f1_score(test_target,prediction,average='weighted')\n",
    "precision=precision_score(test_target,prediction,average='weighted')\n",
    "print('best recall:',recall)\n",
    "print('best accuracy:',acc)\n",
    "print('best f1:',f1)\n",
    "print('best precision:',precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbest_recall=0\\nrecall_list_XGBoost=[]\\nprecision_list_XGBoost=[]\\nxgb_train_target=DataProcessing.numerical_target(train_target)\\nxgb_test_target=DataProcessing.numerical_target(test_target)\\n#Talvez não tenha parametro random_state\\n#Tem parametro learning rate, talvez vale a pena testar\\nfor estimators in tqdm(range(1,100)):\\n    for depth in range(1,15):\\n        model = xgb.XGBClassifier(n_estimators=estimators,max_depth=depth, random_state=12345)\\n        model.fit(train_data,xgb_train_target)\\n        prediction=model.predict(test_data)\\n        recall=recall_score(xgb_test_target,prediction)\\n        precision=precision_score(xgb_test_target,prediction)\\n        recall_list_XGBoost.append(recall)\\n        precision_list_XGBoost.append(precision)\\n        if best_recall<recall:\\n            best_depth=depth\\n            best_recall=recall\\n            best_estimators=estimators\\n            best_acc=accuracy_score(test_target,prediction)\\n            best_f1=f1_score(test_target,prediction)\\n            best_precision=precision\\nprint('best depth:',best_depth)\\nprint('best number of estimators:',best_estimators)\\nprint('best recall:',best_recall)\\nprint('best accuracy:',best_acc)\\nprint('best f1:',best_f1)\\nprint('best precision:',best_precision) \\n\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consertar kernel e dependencias \n",
    "\"\"\"\n",
    "best_recall=0\n",
    "recall_list_XGBoost=[]\n",
    "precision_list_XGBoost=[]\n",
    "xgb_train_target=DataProcessing.numerical_target(train_target)\n",
    "xgb_test_target=DataProcessing.numerical_target(test_target)\n",
    "#Talvez não tenha parametro random_state\n",
    "#Tem parametro learning rate, talvez vale a pena testar\n",
    "for estimators in tqdm(range(1,100)):\n",
    "    for depth in range(1,15):\n",
    "        model = xgb.XGBClassifier(n_estimators=estimators,max_depth=depth, random_state=12345)\n",
    "        model.fit(train_data,xgb_train_target)\n",
    "        prediction=model.predict(test_data)\n",
    "        recall=recall_score(xgb_test_target,prediction)\n",
    "        precision=precision_score(xgb_test_target,prediction)\n",
    "        recall_list_XGBoost.append(recall)\n",
    "        precision_list_XGBoost.append(precision)\n",
    "        if best_recall<recall:\n",
    "            best_depth=depth\n",
    "            best_recall=recall\n",
    "            best_estimators=estimators\n",
    "            best_acc=accuracy_score(test_target,prediction)\n",
    "            best_f1=f1_score(test_target,prediction)\n",
    "            best_precision=precision\n",
    "print('best depth:',best_depth)\n",
    "print('best number of estimators:',best_estimators)\n",
    "print('best recall:',best_recall)\n",
    "print('best accuracy:',best_acc)\n",
    "print('best f1:',best_f1)\n",
    "print('best precision:',best_precision) \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [04:34<00:00,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best depth: 1\n",
      "best number of estimators: 4\n",
      "best recall: 0.7518939393939394\n",
      "best accuracy: 0.7518939393939394\n",
      "best f1: 0.696439906609398\n",
      "best precision: 0.6952480292332154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_recall=0\n",
    "recall_list_adaboost=[]\n",
    "precision_list_adaboost=[]\n",
    "#Talvez não tenha parametro  ou random_state\n",
    "#Talvez tenha parametro learning rate, talvez vale a pena testar\n",
    "for estimators in tqdm(range(1,100)):\n",
    "    for depth in range(1,10):\n",
    "        model = AdaBoostClassifier(n_estimators=estimators, random_state=12345)\n",
    "        model.fit(train_data,train_target)\n",
    "        prediction=model.predict(test_data)\n",
    "        recall=recall_score(test_target,prediction,average='weighted')\n",
    "        precision=precision_score(test_target,prediction,average='weighted',zero_division=0)\n",
    "        recall_list_adaboost.append(recall)\n",
    "        precision_list_adaboost.append(precision)\n",
    "        if best_recall<recall:\n",
    "            best_model=model\n",
    "            best_depth=depth\n",
    "            best_recall=recall\n",
    "            best_estimators=estimators\n",
    "            best_acc=accuracy_score(test_target,prediction)\n",
    "            best_f1=f1_score(test_target,prediction,average='weighted')\n",
    "            best_precision=precision\n",
    "print('best depth:',best_depth)\n",
    "print('best number of estimators:',best_estimators)\n",
    "print('best recall:',best_recall)\n",
    "print('best accuracy:',best_acc)\n",
    "print('best f1:',best_f1)\n",
    "print('best precision:',best_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floresta Aleatoria sem Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:13<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best depth: 29\n",
      "best size: 49\n",
      "best recall: 0.7916666666666666\n",
      "best accuracy: 0.7916666666666666\n",
      "best f1: 0.7482110833482369\n",
      "best precision: 0.7760184976969774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_recall=0\n",
    "recall_list_florest=[]\n",
    "precision_list_florest=[]\n",
    "for size in tqdm(range(1,50)):\n",
    "    for depth in range(1,30):\n",
    "        model=RandomForestClassifier(random_state=123456789,max_depth=depth,n_estimators=size)\n",
    "        model.fit(train_data,train_target)\n",
    "        prediction=model.predict(test_data)\n",
    "        recall=recall_score(test_target,prediction,average='weighted')\n",
    "        precision=precision_score(test_target,prediction,average='weighted',zero_division=0)\n",
    "        recall_list_florest.append(recall)\n",
    "        precision_list_florest.append(precision)\n",
    "        if best_recall<recall:\n",
    "            best_depth=depth\n",
    "            best_recall=recall\n",
    "            best_size=size\n",
    "            best_acc=accuracy_score(test_target,prediction)\n",
    "            best_f1=f1_score(test_target,prediction,average='weighted')\n",
    "            best_precision=precision\n",
    "print('best depth:',best_depth)\n",
    "print('best size:',best_size)\n",
    "print('best recall:',best_recall)\n",
    "print('best accuracy:',best_acc)\n",
    "print('best f1:',best_f1)\n",
    "print('best precision:',best_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arvore de decisão sem Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:04<00:00, 22.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best depth: 73\n",
      "best recall: 0.8200757575757576\n",
      "best accuracy: 0.8200757575757576\n",
      "best f1: 0.8145825710876146\n",
      "best precision: 0.8092480294455772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_recall=0\n",
    "recall_list_tree=[]\n",
    "precision_list_tree=[]\n",
    "for depth in tqdm(range(1,100)):\n",
    "    model=DecisionTreeClassifier(random_state=123456789,max_depth=depth)\n",
    "    model.fit(train_data,train_target)\n",
    "    prediction=model.predict(test_data)\n",
    "    recall=recall_score(test_target,prediction,average='weighted')\n",
    "    precision=precision_score(test_target,prediction,average='weighted',zero_division=0)\n",
    "    recall_list_tree.append(recall)\n",
    "    precision_list_tree.append(precision)\n",
    "    if best_recall<recall:\n",
    "        best_depth=depth\n",
    "        best_recall=recall\n",
    "        best_acc=accuracy_score(test_target,prediction)\n",
    "        best_f1=f1_score(test_target,prediction,average='weighted')\n",
    "        best_precision=precision\n",
    "print('best depth:',best_depth)\n",
    "print('best recall:',best_recall)\n",
    "print('best accuracy:',best_acc)\n",
    "print('best f1:',best_f1)\n",
    "print('best precision:',best_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive-Bayes sem sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best recall: 0.7329545454545454\n",
      "best accuracy: 0.7329545454545454\n",
      "best f1: 0.7511976381461676\n",
      "best precision: 0.8044400527009222\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(train_data.toarray(),train_target)\n",
    "prediction=model.predict(test_data.toarray())\n",
    "recall=recall_score(test_target,prediction,average='weighted')\n",
    "acc=accuracy_score(test_target,prediction)\n",
    "f1=f1_score(test_target,prediction,average='weighted')\n",
    "precision=precision_score(test_target,prediction,average='weighted')\n",
    "print('best recall:',recall)\n",
    "print('best accuracy:',acc)\n",
    "print('best f1:',f1)\n",
    "print('best precision:',precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva Recall-Precision dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['High' 'Medium' 'Not Violence' 'VeryHight' 'Low']\n",
      "1199\n",
      "5\n",
      "17\n",
      "93\n",
      "444\n"
     ]
    }
   ],
   "source": [
    "print(target.unique())\n",
    "print(len(target[target=='Not Violence']))\n",
    "print(len(target[target=='Low']))\n",
    "print(len(target[target=='Medium']))\n",
    "print(len(target[target=='High']))\n",
    "print(len(target[target=='VeryHight']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1230 entries, 1392 to 1433\n",
      "Data columns (total 5 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   level_0              1230 non-null   int64  \n",
      " 1   index                1230 non-null   int64  \n",
      " 2   text                 1230 non-null   object \n",
      " 3   Total(SUM)           1229 non-null   float64\n",
      " 4   Classe de Violência  1230 non-null   object \n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 57.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_sampled,garbage=train_test_split(df_final.drop_duplicates().reset_index(), test_size=0.3, random_state=12345,shuffle=True,stratify=df_final['Classe de Violência'])\n",
    "features_sampled,target_sampled=DataProcess.upsample(df_sampled['text'], df_sampled['Classe de Violência'], 240,'Low')\n",
    "features_sampled,target_sampled=DataProcess.upsample(features_sampled,target_sampled, 71,'Medium')\n",
    "features_sampled,target_sampled=DataProcess.upsample(features_sampled,target_sampled, 13,'High')\n",
    "features_sampled,target_sampled=DataProcess.upsample(features_sampled,target_sampled, 3,'VeryHigh')\n",
    "features_sampled=DataProcess.text_preprocessing_nltk(features_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floresta Aleatoria com Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [02:18<00:00,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best depth: 29\n",
      "best size: 21\n",
      "best recall: 0.7632575757575758\n",
      "best accuracy: 0.7632575757575758\n",
      "best f1: 0.7237333848128602\n",
      "best precision: 0.7937946306755943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_recall=0\n",
    "recall_list_florest=[]\n",
    "precision_list_florest=[]\n",
    "for size in tqdm(range(1,50)):\n",
    "    for depth in range(1,30):\n",
    "        model=RandomForestClassifier(random_state=123456789,max_depth=depth,n_estimators=size)\n",
    "        model.fit(features_sampled,target_sampled)\n",
    "        prediction=model.predict(test_data)\n",
    "        recall=recall_score(test_target,prediction,average='weighted')\n",
    "        precision=precision_score(test_target,prediction,average='weighted',zero_division=0)\n",
    "        recall_list_florest.append(recall)\n",
    "        precision_list_florest.append(precision)\n",
    "        if best_recall<recall:\n",
    "            best_model=model\n",
    "            best_depth=depth\n",
    "            best_recall=recall\n",
    "            best_size=size\n",
    "            best_acc=accuracy_score(test_target,prediction)\n",
    "            best_f1=f1_score(test_target,prediction,average='weighted')\n",
    "            best_precision=precision\n",
    "print('best depth:',best_depth)\n",
    "print('best size:',best_size)\n",
    "print('best recall:',best_recall)\n",
    "print('best accuracy:',best_acc)\n",
    "print('best f1:',best_f1)\n",
    "print('best precision:',best_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arvore de decisão com Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:04<00:00, 24.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best depth: 38\n",
      "best recall: 0.7954545454545454\n",
      "best accuracy: 0.7954545454545454\n",
      "best f1: 0.788440383620773\n",
      "best precision: 0.8106343557476484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_recall=0\n",
    "recall_list_tree=[]\n",
    "precision_list_tree=[]\n",
    "for depth in tqdm(range(1,100)):\n",
    "    model=DecisionTreeClassifier(random_state=123456789,max_depth=depth)\n",
    "    model.fit(features_sampled,target_sampled)\n",
    "    prediction=model.predict(test_data)\n",
    "    recall=recall_score(test_target,prediction,average='weighted')\n",
    "    precision=precision_score(test_target,prediction,average='weighted',zero_division=0)\n",
    "    recall_list_tree.append(recall)\n",
    "    precision_list_tree.append(precision)\n",
    "    if best_recall<recall:\n",
    "        best_model=model\n",
    "        best_depth=depth\n",
    "        best_recall=recall\n",
    "        best_acc=accuracy_score(test_target,prediction)\n",
    "        best_f1=f1_score(test_target,prediction,average='weighted')\n",
    "        best_precision=precision\n",
    "print('best depth:',best_depth)\n",
    "print('best recall:',best_recall)\n",
    "print('best accuracy:',best_acc)\n",
    "print('best f1:',best_f1)\n",
    "print('best precision:',best_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive-Bayes com sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best recall: 0.7329545454545454\n",
      "best accuracy: 0.7329545454545454\n",
      "best f1: 0.7511976381461676\n",
      "best precision: 0.7925474785717553\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(features_sampled.toarray(),target_sampled)\n",
    "prediction=model.predict(test_data.toarray())\n",
    "recall=recall_score(test_target,prediction,average='weighted')\n",
    "acc=accuracy_score(test_target,prediction)\n",
    "f1=f1_score(test_target,prediction,average='weighted')\n",
    "print('best recall:',recall)\n",
    "print('best accuracy:',acc)\n",
    "print('best f1:',f1)\n",
    "print('best precision:',precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva Recall-Precision dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por enquanto o melhor modelo entre eles, sem contar o XGBoost, parece ser a arvore de decisão.\n",
    "\n",
    "Parece valer a pena testar a vetorização com por NILC quando testarmos regressão.\n",
    "\n",
    "Normalização da uma pequena melhora em alguns dos modelos, mas talvez seja por coincidencia (a seed ser boa para aquele novo formato de matriz especifica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
